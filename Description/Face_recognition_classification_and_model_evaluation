# Next we are gonna do classification, model fine tuning and evaluation 
* I prepare train and test sets using my model and i gonna train couple models 
* I start from SVC model and i reach very high accuracy
* And i plot my model's predictions on confusion matrix
* I also check classification report and reach average f1-score 0.92, which is very good

# Then i gonna check couple other models
* I put them into the model list and train on my train set 
* Then take predictions and check the score results
* And i see that also as good as SVM are models: LogisticRegression and LinearDiscriminant

# I want to reach the highest score as possible, so i gonna use cross_val_score technique
* So i supply Kflod model, set data splits to 5, then shuffle the data
* Next i supply my models to the cross_val_score, next X and Y variables and KFold model
* Finally i can take mean score from all scores 
* I see that 3 model reach high accuracy: LinearDiscriminant, LogisticRegression and SVC 
* Then i check confusion_matrix on my LinearDiscriminant model, when i check average f1-score its 0.94 which is pretty high

# Next i gonna do further model tuning
* I use LeaveOneOut model, which leave only 1 sample for testing 
* So i feed in to the cross_val_score LogisticRegression, which achieve score: 0.97
* And LinearDiscriminant, which achieve score: 0.99
* So still LinearDiscriminat win with other models

# Then i gonna illustrate precision and recall curves with help of signature module and plt
* First i gonna binarize my 40 classes 
* When i check the target shape its 400 by 40 and first target is just row vector with 39 zeros and 1 in place of corect class num.

# Then i create new train and test set for multiclass classification
* I use PCA on given X_train and transform using PCA X_train and X_test
* To do multi class classification we are gonna use One VS Rest Classifier

# What its doing is following: its splitting a multi class dataset into multiple binary classification problems
* Fortunately we have only 40 classes, because thera are some issues with very large number of classes
* It's because for each class ther's need to be create one model
* And one vs rest is because 40 classes dataset can be devided into 40 binary classification datasets
* Por example 1 vs (2-40), then 2 vs (1-40) without 2 and on

# Then i call OneVsRestClassifier on my LinearDiscriminant
